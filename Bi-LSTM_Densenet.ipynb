{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a974d819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T17:23:16.392229Z",
     "iopub.status.busy": "2025-04-02T17:23:16.391892Z",
     "iopub.status.idle": "2025-04-02T17:23:22.683173Z",
     "shell.execute_reply": "2025-04-02T17:23:22.681842Z"
    },
    "papermill": {
     "duration": 6.297021,
     "end_time": "2025-04-02T17:23:22.685089",
     "exception": false,
     "start_time": "2025-04-02T17:23:16.388068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Number of bird species (trained): 146\n",
      "Total species in submission: 206\n",
      "Number of non-bird species: 60\n",
      "Models loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-565754f8382a>:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_binary.load_state_dict(torch.load(\"/kaggle/input/bi-lstm-densenet/model_binary_state_dict.pth\", map_location=device))\n",
      "<ipython-input-1-565754f8382a>:137: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_multiclass.load_state_dict(torch.load(\"/kaggle/input/bi-lstm-densenet/model_multiclass_state_dict.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 test soundscapes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test files: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission dataframe...\n",
      "Submission saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ----------------------------\n",
    "# Configuration\n",
    "# ----------------------------\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.test_soundscapes = \"/kaggle/input/birdclef-2025/test_soundscapes\"   # folder with test audio files\n",
    "        self.submission_csv = \"/kaggle/input/birdclef-2025/sample_submission.csv\"  # sample submission file\n",
    "        self.debug = False\n",
    "        self.debug_count = 10  # use only in debug mode\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() \n",
    "                      else \"cuda\" if torch.cuda.is_available() \n",
    "                      else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ----------------------------\n",
    "# Model Architecture: BiLSTMDenseNet\n",
    "# ----------------------------\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, n_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(n_layers):\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.BatchNorm2d(in_channels + i * growth_rate),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(in_channels + i * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "            ))\n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for layer in self.layers:\n",
    "            new_feature = layer(torch.cat(features, dim=1))\n",
    "            features.append(new_feature)\n",
    "        return torch.cat(features, dim=1)\n",
    "\n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class BiLSTMDenseNet(nn.Module):\n",
    "    def __init__(self, num_classes, growth_rate=16, num_dense_layers=4, \n",
    "                 lstm_hidden_size=64, lstm_layers=2):\n",
    "        super(BiLSTMDenseNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.denseblock = DenseBlock(32, growth_rate, num_dense_layers)\n",
    "        in_channels_after_dense = 32 + num_dense_layers * growth_rate\n",
    "        self.trans = TransitionLayer(in_channels_after_dense, in_channels_after_dense // 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels_after_dense // 2, 64, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.bi_lstm = nn.LSTM(input_size=64, hidden_size=lstm_hidden_size, \n",
    "                               num_layers=lstm_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2 * lstm_hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.denseblock(x)\n",
    "        x = self.trans(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        # Average over frequency axis (axis=2)\n",
    "        x = torch.mean(x, dim=2)  # shape: (batch, 64, time)\n",
    "        x = x.permute(0, 2, 1)     # reshape to (batch, time, channels) for LSTM\n",
    "        self.bi_lstm.flatten_parameters()\n",
    "        lstm_out, _ = self.bi_lstm(x)\n",
    "        lstm_out = torch.mean(lstm_out, dim=1)\n",
    "        return self.fc(lstm_out)\n",
    "\n",
    "# ----------------------------\n",
    "# Load Models\n",
    "# ----------------------------\n",
    "# Load binary classifier (2 classes: non-bird, bird)\n",
    "model_binary = BiLSTMDenseNet(num_classes=2).to(device)\n",
    "model_binary.load_state_dict(torch.load(\"/kaggle/input/bi-lstm-densenet/model_binary_state_dict.pth\", map_location=device))\n",
    "model_binary.eval()\n",
    "\n",
    "# Load multiclass classifier (trained only on bird species)\n",
    "# We'll re-instantiate based on taxonomy later.\n",
    "model_multiclass = None\n",
    "\n",
    "# ----------------------------\n",
    "# Load Taxonomy and Build Species IDs\n",
    "# ----------------------------\n",
    "taxonomy_df = pd.read_csv(\"/kaggle/input/birdclef-2025/taxonomy.csv\")\n",
    "# Get bird species (Aves) as primary_label; these are the classes the multiclass model predicts.\n",
    "bird_species = sorted(taxonomy_df[taxonomy_df['class_name'] == 'Aves']['primary_label'].astype(str).unique())\n",
    "nBird = len(bird_species)\n",
    "print(\"Number of bird species (trained):\", nBird)\n",
    "\n",
    "# Load sample submission to get the full set of 206 species\n",
    "sample_sub = pd.read_csv(cfg.submission_csv)\n",
    "submission_species = list(sample_sub.columns[1:])  # skip row_id\n",
    "nTotal = len(submission_species)\n",
    "print(\"Total species in submission:\", nTotal)\n",
    "\n",
    "# Non-bird species: those in submission but not in bird_species.\n",
    "nonbird_species = [sp for sp in submission_species if sp not in bird_species]\n",
    "nNonBird = len(nonbird_species)\n",
    "print(\"Number of non-bird species:\", nNonBird)\n",
    "\n",
    "species_ids = {\n",
    "    'bird': bird_species,\n",
    "    'nonbird': nonbird_species,\n",
    "    'submission': submission_species\n",
    "}\n",
    "\n",
    "# Re-instantiate the multiclass model with correct number of classes (nBird)\n",
    "model_multiclass = BiLSTMDenseNet(num_classes=nBird).to(device)\n",
    "model_multiclass.load_state_dict(torch.load(\"/kaggle/input/bi-lstm-densenet/model_multiclass_state_dict.pth\", map_location=device))\n",
    "model_multiclass.eval()\n",
    "\n",
    "print(\"Models loaded.\")\n",
    "\n",
    "# ----------------------------\n",
    "# Define Mel-Spectrogram Transform\n",
    "# ----------------------------\n",
    "sample_rate = 32000\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=sample_rate, n_mels=64, n_fft=1024\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Test-Time Augmentation (TTA)\n",
    "# ----------------------------\n",
    "def apply_tta(spec, tta_idx):\n",
    "    \"\"\"Apply TTA to a spectrogram (numpy array).\"\"\"\n",
    "    if tta_idx == 0:\n",
    "        return spec\n",
    "    elif tta_idx == 1:\n",
    "        return np.flip(spec, axis=1)  # horizontal flip (time shift)\n",
    "    elif tta_idx == 2:\n",
    "        return np.flip(spec, axis=0)  # vertical flip (frequency shift)\n",
    "    else:\n",
    "        return spec\n",
    "\n",
    "# ----------------------------\n",
    "# Sliding Window Inference Function (5-second chunks)\n",
    "# ----------------------------\n",
    "import librosa\n",
    "\n",
    "def predict_on_spectrogram(audio_path, models, cfg, species_ids):\n",
    "    \"\"\"\n",
    "    Process a test audio file by splitting it into non-overlapping 5-second chunks.\n",
    "    For each chunk:\n",
    "      - Compute Mel-spectrogram.\n",
    "      - Apply TTA (tta_idx 0, 1, 2) and average binary predictions to get pb.\n",
    "      - If pb > threshold, apply TTA with the multiclass model to get bird probabilities (scaled by pb).\n",
    "      - Otherwise, assign zeros for bird predictions.\n",
    "      - For non-bird species, assign uniform probability = (1 - pb) / nNonBird.\n",
    "      - Construct a final prediction vector of length nTotal (206) following the order in species_ids['submission'].\n",
    "      - Generate row_id as \"H02_20230420_074000_5\", \"H02_20230420_074000_10\", etc.\n",
    "    Return a list of (row_id, final_pred) tuples.\n",
    "    \"\"\"\n",
    "    # Load the audio using librosa: force a sample rate of 32000 and convert to mono.\n",
    "    waveform_np, sr = librosa.load(audio_path, sr=sample_rate, mono=True)\n",
    "    # Convert the numpy array to a torch tensor and add a channel dimension (shape becomes [1, total_samples])\n",
    "    waveform = torch.tensor(waveform_np).unsqueeze(0)\n",
    "    \n",
    "    # Set chunk duration to 5 seconds\n",
    "    chunk_duration = 5.0\n",
    "    chunk_size = int(chunk_duration * sample_rate)\n",
    "    total_samples = waveform.shape[1]\n",
    "    num_chunks = total_samples // chunk_size\n",
    "    \n",
    "    results = []\n",
    "    base_id = os.path.basename(audio_path).split('.')[0]\n",
    "    \n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_size\n",
    "        chunk = waveform[:, start:start+chunk_size]\n",
    "        spec = mel_transform(chunk)  # shape: (1, n_mels, time)\n",
    "        spec = spec.unsqueeze(0).to(device)  # add batch dimension\n",
    "        \n",
    "        # Apply TTA for binary classifier\n",
    "        tta_bin_preds = []\n",
    "        for tta_idx in [0, 1, 2]:\n",
    "            spec_tta = apply_tta(spec.cpu().numpy()[0], tta_idx)\n",
    "            spec_tta = torch.tensor(spec_tta).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                out_bin = models['binary'](spec_tta)\n",
    "                prob_bin = torch.softmax(out_bin, dim=1)\n",
    "            tta_bin_preds.append(prob_bin.cpu().numpy()[0, 1])\n",
    "        pb = np.mean(tta_bin_preds)\n",
    "        nonbird_prob = 1 - pb\n",
    "        \n",
    "        binary_threshold = 0.5\n",
    "        if pb > binary_threshold:\n",
    "            tta_multi_preds = []\n",
    "            for tta_idx in [0, 1, 2]:\n",
    "                spec_tta = apply_tta(spec.cpu().numpy()[0], tta_idx)\n",
    "                spec_tta = torch.tensor(spec_tta).unsqueeze(0).to(device)\n",
    "                with torch.no_grad():\n",
    "                    out_multi = models['multiclass'](spec_tta)\n",
    "                    prob_multi = torch.softmax(out_multi, dim=1)\n",
    "                tta_multi_preds.append(prob_multi.cpu().numpy()[0])\n",
    "            avg_bird_probs = np.mean(tta_multi_preds, axis=0)\n",
    "            bird_probs = pb * avg_bird_probs\n",
    "        else:\n",
    "            bird_probs = np.zeros(len(species_ids['bird']))\n",
    "        \n",
    "        nonbird_probs = np.full((len(species_ids['nonbird']),), nonbird_prob / len(species_ids['nonbird']))\n",
    "        \n",
    "        final_pred = np.zeros(nTotal)\n",
    "        for j, sp in enumerate(species_ids['submission']):\n",
    "            if sp in species_ids['bird']:\n",
    "                idx = species_ids['bird'].index(sp)\n",
    "                final_pred[j] = bird_probs[idx]\n",
    "            else:\n",
    "                final_pred[j] = nonbird_probs[species_ids['nonbird'].index(sp)]\n",
    "        \n",
    "        # Generate row_id: simply concatenate the base filename with \"_\" and (i*5 + 5)\n",
    "        row_id = base_id + f'_{i*5 + 5}'\n",
    "        results.append((row_id, final_pred))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# ----------------------------\n",
    "# Inference and Submission Generation\n",
    "# ----------------------------\n",
    "def run_inference(cfg, models, species_ids):\n",
    "    test_files = list(Path(cfg.test_soundscapes).glob('*.ogg'))\n",
    "    if cfg.debug:\n",
    "        print(f\"Debug mode enabled: using only {cfg.debug_count} files\")\n",
    "        test_files = test_files[:cfg.debug_count]\n",
    "    print(f\"Found {len(test_files)} test soundscapes\")\n",
    "    \n",
    "    all_row_ids = []\n",
    "    all_predictions = []\n",
    "    for audio_path in tqdm(test_files, desc=\"Processing test files\"):\n",
    "        rows = predict_on_spectrogram(str(audio_path), models, cfg, species_ids)\n",
    "        for row_id, pred in rows:\n",
    "            all_row_ids.append(row_id)\n",
    "            all_predictions.append(pred)\n",
    "    return all_row_ids, all_predictions\n",
    "\n",
    "def create_submission(row_ids, predictions, species_ids, cfg):\n",
    "    print(\"Creating submission dataframe...\")\n",
    "    submission_dict = {'row_id': row_ids}\n",
    "    for i, sp in enumerate(species_ids['submission']):\n",
    "        submission_dict[sp] = [pred[i] for pred in predictions]\n",
    "    submission_df = pd.DataFrame(submission_dict)\n",
    "    \n",
    "    # Ensure we match sample submission columns\n",
    "    sample_sub = pd.read_csv(cfg.submission_csv)\n",
    "    ordered_columns = ['row_id'] + list(sample_sub.columns[1:])\n",
    "    submission_df = submission_df[ordered_columns]\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "# ----------------------------\n",
    "# Main Inference and Submission Generation\n",
    "# ----------------------------\n",
    "# Build species_ids dictionary using taxonomy and sample submission.\n",
    "bird_species = sorted(taxonomy_df[taxonomy_df['class_name'] == 'Aves']['primary_label'].astype(str).unique())\n",
    "sample_sub = pd.read_csv(cfg.submission_csv)\n",
    "submission_species = list(sample_sub.columns[1:])  # skip row_id column\n",
    "nonbird_species = [sp for sp in submission_species if sp not in bird_species]\n",
    "\n",
    "species_ids = {\n",
    "    'bird': bird_species,\n",
    "    'nonbird': nonbird_species,\n",
    "    'submission': submission_species\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'binary': model_binary,\n",
    "    'multiclass': model_multiclass\n",
    "}\n",
    "\n",
    "all_row_ids, all_predictions = run_inference(cfg, models, species_ids)\n",
    "submission_df = create_submission(all_row_ids, all_predictions, species_ids, cfg)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission saved to submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8899e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-02T17:23:22.690988Z",
     "iopub.status.busy": "2025-04-02T17:23:22.690689Z",
     "iopub.status.idle": "2025-04-02T17:23:22.712744Z",
     "shell.execute_reply": "2025-04-02T17:23:22.711790Z"
    },
    "papermill": {
     "duration": 0.026566,
     "end_time": "2025-04-02T17:23:22.714388",
     "exception": false,
     "start_time": "2025-04-02T17:23:22.687822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>1139490</th>\n",
       "      <th>1192948</th>\n",
       "      <th>1194042</th>\n",
       "      <th>126247</th>\n",
       "      <th>1346504</th>\n",
       "      <th>134933</th>\n",
       "      <th>135045</th>\n",
       "      <th>1462711</th>\n",
       "      <th>1462737</th>\n",
       "      <th>...</th>\n",
       "      <th>yebfly1</th>\n",
       "      <th>yebsee1</th>\n",
       "      <th>yecspi2</th>\n",
       "      <th>yectyr1</th>\n",
       "      <th>yehbla2</th>\n",
       "      <th>yehcar1</th>\n",
       "      <th>yelori1</th>\n",
       "      <th>yeofly1</th>\n",
       "      <th>yercac1</th>\n",
       "      <th>ywcpar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [row_id, 1139490, 1192948, 1194042, 126247, 1346504, 134933, 135045, 1462711, 1462737, 1564122, 21038, 21116, 21211, 22333, 22973, 22976, 24272, 24292, 24322, 41663, 41778, 41970, 42007, 42087, 42113, 46010, 47067, 476537, 476538, 48124, 50186, 517119, 523060, 528041, 52884, 548639, 555086, 555142, 566513, 64862, 65336, 65344, 65349, 65373, 65419, 65448, 65547, 65962, 66016, 66531, 66578, 66893, 67082, 67252, 714022, 715170, 787625, 81930, 868458, 963335, amakin1, amekes, ampkin1, anhing, babwar, bafibi1, banana, baymac, bbwduc, bicwre1, bkcdon, bkmtou1, blbgra1, blbwre1, blcant4, blchaw1, blcjay1, blctit1, blhpar1, blkvul, bobfly1, bobher1, brtpar1, bubcur1, bubwre1, bucmot3, bugtan, butsal1, cargra1, cattyr, chbant1, chfmac1, cinbec1, cocher1, cocwoo1, colara1, colcha1, compau, compot1, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 207 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verifying format\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "isSourceIdPinned": false,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 6916281,
     "sourceId": 11094916,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.521241,
   "end_time": "2025-04-02T17:23:24.239101",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-02T17:23:13.717860",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
